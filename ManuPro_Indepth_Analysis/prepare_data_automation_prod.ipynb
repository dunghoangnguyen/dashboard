{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c36b15-e4e4-4050-82ef-77f5e93a7291",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import timedelta\n",
    "from operator import attrgetter\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "861bb0c4-195a-46bb-9700-2d8336bc9d97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1. Modify the config and paths for upcoming month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c0de842-7c2c-4d50-9429-6b920def32c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#change filter date and tier if needed every month\n",
    "max_date_str = '2023-12-31'\n",
    "min_last_mth = '2023-11-30'\n",
    "min_last_3m = '2023-09-30' # last 3 month\n",
    "min_date_str = '2022-12-31' # only last year\n",
    "max_date = pd.to_datetime(max_date_str)\n",
    "mth_partition = max_date_str[:7]\n",
    "current_year = max_date.year\n",
    "\n",
    "# offline data, manual work for manuprolist and VN model output. please control the format to align with previous month\n",
    "# Convert yyyymmdd_Platinum_list.xlsx into vn_mp_yyyymm.csv and upload to DBx hive_metastore/default\n",
    "path_manupro = 'vn_mp_202312'\n",
    "# Convert yyyymmdd_Platinum_monthly_allowance.xlsx into manu_pro_tracking_yyyymmdd.csv and upload to DBx hive_metastore/default\n",
    "path_allowance = 'manu_pro_tracking_20231231'\n",
    "# Convert yyyymmdd_MDRT_list.xlsx into vn_mdrt_yyyymmdd.csv and upload to DBx hive_metastore/default\n",
    "path_mdrt = 'vn_mdrt_20230920'\n",
    "manupro_level = 'Platinum'\n",
    "snapshot = '202312' # used to filter lapse socre and persistency socre\n",
    "\n",
    "# model output tables, please change the date\n",
    "multiclass_path = '/dbfs/mnt/lab/vn/project/scratch/gen_rep_2023/prod_existing/11_multiclass_scored_base/multiclass_scored_' + snapshot + '.csv'\n",
    "leads_model_path = '/dbfs/mnt/lab/vn/project/scratch/gen_rep_2023/prod_existing/8_model_score_existing/'\n",
    "lapse_path = '/dbfs/mnt/lab/vn/project/lapse/pre_lapse_deployment/lapse_mthly/lapse_score.parquet/'\n",
    "\n",
    "# pre_lapse_revamp_path = '/dbfs/mnt/lab/vn/project/lapse/pre_lapse_revamp_3/snapshots/snapshots_202309/'\n",
    "\n",
    "# manupro intro link\n",
    "mp_link_url = 'https://manulife-mba.axonify.com/training/index.html#hub/search/community-1535/articles/1'\n",
    "#2024 MDRT requirment\n",
    "ape_benchmark = dict({'MDRT': 721626600, 'COT': 2164879800, 'TOT': 4329759600, '^.^': 4329759600})\n",
    "\n",
    "# output files to\n",
    "out_path = '/dbfs/mnt/lab/vn/project/temp_luobinr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a2a58cd-d5a7-4445-9a2d-50c0db858d74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load dependency model output\n",
    "multiclass = pd.read_csv(multiclass_path) # new file for csv every month\n",
    "leads_existing_model = pd.read_parquet(leads_model_path)\n",
    "lapse = pd.read_parquet(lapse_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc1a9a08-c24d-48eb-a89f-aa2b46c7b29f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# step 2. load PAR related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdf68201-b9d9-4753-820b-501d5972d3e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select * \n",
    "from {0} \n",
    "where level = '{1}';\n",
    "'''.format(path_manupro, manupro_level)\n",
    "mp = spark.sql(query).toPandas()\n",
    "\n",
    "query = '''\n",
    "select * \n",
    "from {0} \n",
    ";\n",
    "'''.format(path_allowance)\n",
    "mth_allowance = spark.sql(query).toPandas()\n",
    "\n",
    "query = '''\n",
    "select * \n",
    "from {0} \n",
    ";\n",
    "'''.format(path_mdrt)\n",
    "mdrt = spark.sql(query).toPandas()\n",
    "\n",
    "\n",
    "path = '/dbfs/mnt/prod/Curated/VN/Master/VN_CURATED_DATAMART_DB/TAGTDM_DAILY'\n",
    "tagtdm_daily = pd.read_parquet(path)\n",
    "#tagtdm_daily = tagtdm_daily[tagtdm_daily['agt_code'].isin(mp['agt_cd'])]\n",
    "\n",
    "\n",
    "path = '/dbfs/mnt/prod/Published/VN/Master/VN_PUBLISHED_AMS_DB/TAMS_AGENTS/AMS_TAMS_AGENTS.parquet'\n",
    "tams_agents = pd.read_parquet(path)\n",
    "\n",
    "\n",
    "path = '/dbfs/mnt/prod/Curated/VN/Master/VN_CURATED_ANALYTICS_DB/AGENT_RFM/monthend_dt=' + mth_partition\n",
    "agent_rfm = pd.read_parquet(path)\n",
    "\n",
    "\n",
    "query = '''\n",
    "select pol_num, cli_num, cvg_eff_dt, plan_code, cvg_prem, cvg_typ, cvg_reasn, occp_clas, par_code, bnft_dur, prem_dur, rel_to_insrd, smkr_code, sex_code, \n",
    "cvg_eff_age, cvg_stat_cd, cvg_del_dt, face_amt \n",
    "from hive_metastore.vn_published_cas_db.tcoverages \n",
    "where pol_num in (\n",
    "    select pol_num from hive_metastore.vn_published_cas_db.tpolicys\n",
    "    where wa_cd_1 in (\n",
    "        select agt_cd from {0} \n",
    "        where level = '{1}'\n",
    "    )\n",
    ") or cvg_eff_dt > '{2}'\n",
    ";\n",
    "'''.format(path_manupro, manupro_level, min_last_mth)\n",
    "tcoverages = spark.sql(query).toPandas()\n",
    "\n",
    "\n",
    "query = '''\n",
    "select pol_num, pol_app_dt, pol_eff_dt, sbmt_dt, pol_trmn_dt, pmt_mode, agt_code, wa_cd_1, wa_cd_2, plan_code_base, plan_prem, dist_chnl_cd, pol_stat_cd, pd_to_dt \n",
    "from hive_metastore.vn_published_cas_db.tpolicys\n",
    "where wa_cd_1 in (\n",
    "    select agt_cd from {0} \n",
    "    where level = '{1}'\n",
    ") or pol_num in (\n",
    "    select pol_num from hive_metastore.vn_published_cas_db.tcoverages \n",
    "    where cvg_eff_dt > '{2}'\n",
    ")\n",
    ";\n",
    "'''.format(path_manupro, manupro_level, min_last_mth)\n",
    "tpolicys = spark.sql(query).toPandas()\n",
    "\n",
    "\n",
    "path = '/dbfs/mnt/prod/Published/VN/Master/VN_PUBLISHED_CAS_DB/TCLIENT_POLICY_LINKS/CAS_TCLIENT_POLICY_LINKS.parquet'\n",
    "cus_pol_link = pd.read_parquet(path,columns = ['POL_NUM', 'CLI_NUM', 'LINK_TYP', 'REC_STATUS', 'REL_TO_INSRD'])\n",
    "cus_pol_link = cus_pol_link[cus_pol_link['POL_NUM'].isin(tpolicys['pol_num'])]\n",
    "\n",
    "\n",
    "path = '/dbfs/mnt/prod/Published/VN/Master/VN_PUBLISHED_AMS_DB/TAMS_CANDIDATES/AMS_TAMS_CANDIDATES.parquet'\n",
    "tams_candidates = pd.read_parquet(path, columns = ['ID_NUM', 'CAN_NUM'])\n",
    "\n",
    "\n",
    "path = '/dbfs/mnt/prod/Published/VN/Master/VN_PUBLISHED_CAS_DB/TCLIENT_DETAILS/CAS_TCLIENT_DETAILS.parquet'\n",
    "tclient_details = pd.read_parquet(path, columns = ['ID_NUM', 'CLI_NUM', 'BIRTH_DT', 'SEX_CODE', 'CLI_NM'])\n",
    "\n",
    "\n",
    "path = '/dbfs/mnt/prod/Published/VN/Master/VN_PUBLISHED_CAMPAIGN_FILEBASED_DB/NBV_MARGIN_HISTORIES/NBV_MARGIN_HISTORIES.parquet'\n",
    "margin = pd.read_parquet(path)\n",
    "\n",
    "\n",
    "query = '''\n",
    "select distinct \n",
    "  tclaim.clm_id\n",
    ", tclaim.event_dt\n",
    ", tclaim.clm_recv_dt\n",
    ", tclaim.clm_aprov_dt\n",
    ", tclaim.clm_stat_code\n",
    ", tclaim.clm_reasn_cd\n",
    "\n",
    ", tclaim.plan_code\n",
    ", tclaim.clm_code\n",
    ", tclaim.clm_aprov_amt\n",
    ", case \n",
    "    when tclaim.clm_stat_code = 'A' then tclaim.clm_aprov_amt \n",
    "    else 0 \n",
    "  end as adj_aprov_amt \n",
    ", tclaim.clm_prvd_amt\n",
    ", tclaim.pol_num\n",
    ", tclaim.cli_num\n",
    "from hive_metastore.vn_published_cas_db.tclaim_details as tclaim\n",
    "where tclaim.pol_num in (\n",
    "        select pol_num from hive_metastore.vn_published_cas_db.tpolicys\n",
    "    where wa_cd_1 in (\n",
    "        select agt_cd from {0} \n",
    "        where level = '{1}'\n",
    "    )\n",
    ")\n",
    ";\n",
    "'''.format(path_manupro, manupro_level)\n",
    "tclaim = spark.sql(query).toPandas()\n",
    "\n",
    "\n",
    "path = '/dbfs/mnt/prod/Published/VN/Master/VN_PUBLISHED_CAS_DB/TPLANS/CAS_TPLANS.parquet'\n",
    "sp_plan = pd.read_parquet(path, columns = ['PLAN_CODE', 'SNGL_PREM_IND'])\n",
    "sp_plan = sp_plan[sp_plan['SNGL_PREM_IND'] == 'Y']['PLAN_CODE'].to_list()\n",
    "\n",
    "\n",
    "query = '''\n",
    "select agt_cd, acum_bal as m19_per\n",
    "from hive_metastore.VN_PUBLISHED_AMS_BAK_DB.TAMS_AGT_ACUMS_BK\n",
    "where agt_cd in (\n",
    "    select agt_cd from {0} \n",
    "    where level = '{1}'\n",
    ") and run_num = '{2}'\n",
    "and acum_cd = 'A214'\n",
    ";\n",
    "'''.format(path_manupro, manupro_level, snapshot)\n",
    "m19_per_vn = spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71739343-5191-4dd4-8dea-4df6e374211c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 3. processing for related tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a740820-aa6a-4b00-ad0c-68c57b811b6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# column name issue\n",
    "tams_agents.columns = [i.lower() for i in tams_agents.columns]\n",
    "tams_candidates.columns = [i.lower() for i in tams_candidates.columns]\n",
    "tclient_details.columns = [i.lower() for i in tclient_details.columns]\n",
    "cus_pol_link.columns = [i.lower() for i in cus_pol_link.columns]\n",
    "margin.columns = [i.lower() for i in margin.columns]\n",
    "\n",
    "# addtional agents' demographics\n",
    "\n",
    "agent_rfm = agent_rfm.sort_values(by = ['mar_stat_cd', 'ins_exp_ind']).reset_index(drop = True)\n",
    "agent_rfm = agent_rfm.drop_duplicates(subset = ['agt_code'], keep = 'first').reset_index(drop = True)\n",
    "\n",
    "mar_stat_cd = dict(zip(agent_rfm['agt_code'], agent_rfm['mar_stat_cd']))\n",
    "ins_exp_ind = dict(zip(agent_rfm['agt_code'], agent_rfm['ins_exp_ind']))\n",
    "del agent_rfm\n",
    "\n",
    "tagtdm_daily = tagtdm_daily[~tagtdm_daily['agt_code'].isnull()].reset_index(drop = True)\n",
    "tagtdm_daily['mar_stat_cd'] = tagtdm_daily['agt_code'].map(lambda x: mar_stat_cd[x] if x in mar_stat_cd else np.nan)\n",
    "tagtdm_daily['ins_exp_ind'] = tagtdm_daily['agt_code'].map(lambda x: ins_exp_ind[x] if x in ins_exp_ind else np.nan)\n",
    "\n",
    "tagtdm_daily = tagtdm_daily.rename(columns = {'agt_code': 'wa_cd_1', 'sex_code': 'sex_code_agt'})\n",
    "tagtdm_daily['agt_join_dt'] = pd.to_datetime(tagtdm_daily['agt_join_dt'])\n",
    "tagtdm_daily['agt_term_dt'] = pd.to_datetime(tagtdm_daily['agt_term_dt'])\n",
    "\n",
    "# keep only agents from candidates\n",
    "agt_from_can = list(set(tams_agents['can_num']) & set(tams_candidates['can_num']))\n",
    "tams_can_agt = tams_candidates[tams_candidates['can_num'].isin(pd.Series(agt_from_can))].reset_index(drop = True)\n",
    "del tams_candidates\n",
    "\n",
    "# create id_num to tams_agents\n",
    "agt_can_id = dict(zip(tams_can_agt['can_num'],tams_can_agt['id_num']))\n",
    "tams_agents['id_num'] = tams_agents['can_num'].map(lambda x: agt_can_id[x])\n",
    "\n",
    "id_num_agt_as_cus = list(set(tclient_details['id_num'].to_list()) & set(tams_can_agt['id_num'].to_list()))\n",
    "\n",
    "# create dict of id_num from cli and add to tcoverage\n",
    "tclient_agt = tclient_details[tclient_details['id_num'].isin(id_num_agt_as_cus)].reset_index(drop = True)\n",
    "cli_id_num = dict(zip(tclient_agt['cli_num'], tclient_agt['id_num']))\n",
    "\n",
    "# create dict of id_num from wa_agt and add to tcoverage\n",
    "agt_id_num = dict(zip(tams_agents['agt_code'], tams_agents['id_num']))\n",
    "del tams_agents\n",
    "\n",
    "#only for agency channel\n",
    "tagtdm_daily = tagtdm_daily[(tagtdm_daily['channel'] == 'Agency')&\n",
    "                            (tagtdm_daily['comp_prvd_num'].isin(['01', '98']))&\n",
    "                            (tagtdm_daily['agt_stat_code'] == '1')&\n",
    "                            (tagtdm_daily['agt_term_dt'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57fe3a77-7e50-469f-807b-96e3547a2351",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# processing for policy tables\n",
    "# load coverage data\n",
    "tcoverages['cvg_eff_dt'] = pd.to_datetime(tcoverages['cvg_eff_dt'])\n",
    "tcoverages['cli_id_num_agt_buy'] = tcoverages['cli_num'].map(lambda x: cli_id_num[x] if x in cli_id_num else np.nan)\n",
    "tcoverages['cli_id_num_agt_buy'].notnull().sum()\n",
    "\n",
    "# keep policy from agency channel only\n",
    "tpolicys = tpolicys[tpolicys['wa_cd_1'].isin(tagtdm_daily['wa_cd_1'])].reset_index(drop = True)\n",
    "tpolicys['pol_trmn_dt'] = pd.to_datetime(tpolicys['pol_trmn_dt'])\n",
    "tpolicys['pol_eff_dt'] = pd.to_datetime(tpolicys['pol_eff_dt'])\n",
    "tpolicys['term_pol_last_days'] = (tpolicys['pol_trmn_dt'].dt.date - tpolicys['pol_eff_dt'].dt.date).dt.days\n",
    "tpolicys['agt_id_num_agt_buy'] = tpolicys['wa_cd_1'].map(lambda x: agt_id_num[x] if x in agt_id_num else np.nan)\n",
    "\n",
    "# get pol link all\n",
    "cus_pol_link.rename(columns = {'cli_num':'po_num'}, inplace = True)\n",
    "cus_pol_link = cus_pol_link[(cus_pol_link['link_typ'] == 'O')&(cus_pol_link['rec_status'] == 'A')].reset_index(drop = True)\n",
    "pol_po_dict = dict(zip(cus_pol_link['pol_num'], cus_pol_link['po_num']))\n",
    "po_pol_dict = cus_pol_link.groupby(['po_num'])['pol_num'].max().to_dict()\n",
    "pol_num = pd.Series(list(set(tpolicys['pol_num'].to_list()) & set(tcoverages['pol_num'].to_list())))\n",
    "\n",
    "tcoverages = tcoverages[tcoverages['pol_num'].isin(pol_num)]\n",
    "tpolicys = tpolicys[tpolicys['pol_num'].isin(pol_num)]\n",
    "\n",
    "pol = pd.merge(tcoverages, tpolicys, on = 'pol_num', how = 'left')\n",
    "pol['APE'] = pol['cvg_prem']*12/pol['pmt_mode'].astype(int)\n",
    "\n",
    "#combine to df\n",
    "df = pd.merge(pol, tagtdm_daily, on = 'wa_cd_1', how = 'left')\n",
    "del tpolicys\n",
    "del tcoverages\n",
    "del pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "492dd671-f1ed-4a02-8a01-69ca86f7e33a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# add related columns to df for further calculation\n",
    "df['cvg_prem'] = df['cvg_prem'].astype(float)\n",
    "#create first buy date and repeat buy flag\n",
    "df['po_num'] = df['pol_num'].map(lambda x: pol_po_dict[x] if x in pol_po_dict else np.nan)\n",
    "\n",
    "# adjust APE for first year termination\n",
    "def adjust_ape(eff_days, pmt, prem, ape):\n",
    "    if eff_days <= 21:\n",
    "        ape = 0\n",
    "    else:\n",
    "        if (eff_days is np.nan)|(eff_days >= 365):\n",
    "            ape = ape\n",
    "        elif (eff_days < 365)&(pmt == 12):\n",
    "            ape = ape\n",
    "        elif (eff_days < 365)&(pmt == 3):\n",
    "            ape = prem*(int(eff_days/92)+1)\n",
    "        elif (eff_days < 365)&(pmt == 6):\n",
    "            ape = prem*(int(eff_days/183)+1)\n",
    "        elif (eff_days < 365)&(pmt == 1):\n",
    "            ape = prem*(int(eff_days/31)+1)\n",
    "    return ape\n",
    "\n",
    "df['cvg_del_dt'] = pd.to_datetime(df['cvg_del_dt'])\n",
    "df['min_trmn_dt'] = df[['pol_trmn_dt', 'cvg_del_dt']].min(axis=1)\n",
    "df['pol_eff_days'] = (df['min_trmn_dt'] - df['pol_eff_dt']).dt.days\n",
    "df['adjust_ape'] = list(zip(df['pol_eff_days'], df['pmt_mode'], df['cvg_prem'], df['APE']))\n",
    "df['adjust_ape'] = df['adjust_ape'].map(lambda x: adjust_ape(x[0], x[1], x[2], x[3]))\n",
    "\n",
    "# adjust APE for single premium\n",
    "def adjust_sp_ape(eff_days, prem, adj_ape, sp):\n",
    "    if sp == 0:\n",
    "        ape = adj_ape\n",
    "    else:\n",
    "        if eff_days <= 21:\n",
    "            ape = 0\n",
    "        else: #(eff_days > 21)&(sp != 0):\n",
    "            ape = prem*0.1\n",
    "    return ape\n",
    "\n",
    "# SP list from DB (to be auto updated)\n",
    "# select plan_code, sngl_prem_ind from vn_published_cas_db.tplans where sngl_prem_ind = 'Y'\n",
    "# SP = ['SPU01','SPU02','SPU03','SPU04','UL004','UL005','SCL01','UL035','UL036','UL037']\n",
    "df['sp_ind'] = df['plan_code'].isin(sp_plan).astype(int)\n",
    "\n",
    "df['adjust_ape'] = list(zip(df['pol_eff_days'], df['cvg_prem'], df['adjust_ape'], df['sp_ind']))\n",
    "df['adjust_ape'] = df['adjust_ape'].map(lambda x: adjust_sp_ape(x[0], x[1], x[2], x[3]))\n",
    "\n",
    "df['adjust_ape'] = df['adjust_ape'].astype(float)\n",
    "df['adjust_ape'] = (df['adjust_ape']*1000).astype(int)\n",
    "\n",
    "#prepare columns for KPI calculation\n",
    "df['cvg_eff_yr'] = df['cvg_eff_dt'].dt.year\n",
    "df['cvg_eff_yr_mth'] = df['cvg_eff_dt'].dt.to_period('M')\n",
    "df['cvg_eff_mth_from_pol_eff'] = (df['cvg_eff_dt'].dt.to_period('M').astype(int) - \n",
    "                                    df['pol_eff_dt'].dt.to_period('M').astype(int)\n",
    "                                    ) + 1\n",
    "df['cvg_eff_mth_from_agt_join'] = (df['cvg_eff_dt'].dt.to_period('M').astype(int) -\n",
    "                                    df['agt_join_dt'].dt.to_period('M').astype(int)\n",
    "                                    ) + 1\n",
    "df['pol_eff_mth_from_agt_join'] = (df['pol_eff_dt'].dt.to_period('M').astype(int) - \n",
    "                                    df['agt_join_dt'].dt.to_period('M').astype(int)\n",
    "                                    ) + 1\n",
    "df['pol_eff_days_from_agt_join'] = (df['pol_eff_dt'] - df['agt_join_dt']).dt.days\n",
    "df = df[~df['po_num'].isnull()].reset_index(drop = True)\n",
    "df['po_num'] = df['po_num'].astype(int)\n",
    "\n",
    "stat_dict = dict({'1':'Premium Paying','2':'Premium Waiver','3':'Fully Paid','4':'Extended Term Ins.',\n",
    "                   '5':'Reduced Paid-Up', '6':'Pending for premium', '7':'Support premium',\n",
    "                   '8':'NB Pending', '9':'Support premium', 'A':'Not taken','B':'Lapsed',\n",
    "                    'C':'Converted', 'D': 'Death Claimed', 'E':'Surrendered', 'F': 'Matured', \n",
    "                    'H':'Expired', 'L':'Deleted', 'M': 'MDR Claim', 'N': 'Not taken', \n",
    "                    'R': 'Rejected', 'T': 'TPD Claim', 'X': 'Closed'})\n",
    "\n",
    "df['status'] = df['pol_stat_cd'].map(lambda x: stat_dict[x])\n",
    "\n",
    "df['cvg_active'] = (df['cvg_stat_cd'].isin(['1','2','3','5','7'])).astype(int)\n",
    "df['pol_active'] = (df['pol_stat_cd'].isin(['1','2','3','5','7'])).astype(int)\n",
    "\n",
    "df['pol_eff_yr'] = df['pol_eff_dt'].dt.year\n",
    "\n",
    "# first policy bought, use this one please\n",
    "first_p = df.sort_values(by='pol_eff_dt').drop_duplicates(subset='po_num', keep='first')['pol_num']\n",
    "\n",
    "df['if_first_pol'] = df['pol_num'].isin(first_p).astype(int)\n",
    "df['repeat_sales'] = 1 - df['if_first_pol']\n",
    "\n",
    "tclient_details['birth_dt'] = pd.to_datetime(tclient_details['birth_dt'])\n",
    "tclient_details['age_this_year'] = current_year - tclient_details['birth_dt'].dt.year\n",
    "tclient_details['is_female'] = (tclient_details['sex_code'] == 'F').astype(int)\n",
    "\n",
    "age_this_year_dict = dict(zip(tclient_details['cli_num'], tclient_details['age_this_year']))\n",
    "birth_dict = dict(zip(tclient_details['cli_num'], pd.to_datetime(tclient_details['birth_dt'])))\n",
    "gender_dict = dict(zip(tclient_details['cli_num'], tclient_details['sex_code'].map(lambda x: str(x).upper())))\n",
    "cli_num_name_dict = dict(zip(tclient_details['cli_num'], tclient_details['cli_nm']))\n",
    "del tclient_details\n",
    "\n",
    "\n",
    "df['po_age_this_year'] = df['po_num'].map(lambda x: age_this_year_dict[str(x)] if str(x) in age_this_year_dict else np.nan)\n",
    "df['in_age_this_year'] = df['cli_num'].map(lambda x: age_this_year_dict[x] if x in age_this_year_dict else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab5e74ea-b390-49f0-9a81-ce15367b14b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#some estimation of family relationship and nbv margin\n",
    "\n",
    "# process relationship of beneficiary to insured\n",
    "rel_dict = dict({2:'Spouse',\n",
    "                 1:'Self',\n",
    "                 0:'Others',\n",
    "                 52:'Others',\n",
    "                 51:'Parent',\n",
    "                 3:'Child',\n",
    "                 5:'Others',\n",
    "                 4:'Others',\n",
    "                 10:'Others',\n",
    "                 31:'Others'\n",
    "                })\n",
    "\n",
    "df['insrd'] = df['rel_to_insrd'].astype(int).map(lambda x: rel_dict[x])\n",
    "\n",
    "df['cvg_eff_yr'] = df['cvg_eff_dt'].dt.year\n",
    "\n",
    "#process insured relationship\n",
    "df['be_is_cli'] = (df['insrd'] == 'Self').astype(int)\n",
    "# PO is cli\n",
    "df['po_is_cli'] = (df['po_num'].astype(str) == df['cli_num']).astype(int)\n",
    "df['po_cli_age_gap'] = list(zip(df['po_is_cli'], df['po_age_this_year'], df['in_age_this_year']))\n",
    "df['po_cli_age_gap'] = df['po_cli_age_gap'].map(lambda x: np.nan if x[0] == 1 else x[1] - x[2])\n",
    "\n",
    "df['po_gender'] = df['po_num'].map(lambda x: gender_dict[str(x)] if str(x) in gender_dict else np.nan)\n",
    "df['ins_gender'] = df['cli_num'].map(lambda x: gender_dict[x] if x in gender_dict else np.nan)\n",
    "\n",
    "def which_rela(a,b,c,d):\n",
    "    if a == 1:\n",
    "        y = 'self'\n",
    "    else:\n",
    "        if (b>=18)&(b<=40):\n",
    "            y = 'child'\n",
    "        else:\n",
    "            if b > 40:\n",
    "                y = 'others'\n",
    "            else:\n",
    "                if b < -17:\n",
    "                    y = 'parent'\n",
    "                else:\n",
    "                    if c != d:\n",
    "                        y = 'spouse'\n",
    "                    else:\n",
    "                        y = 'others'\n",
    "    return y\n",
    "\n",
    "df['po_ins_rela'] = list(zip(df['po_is_cli'], df['po_cli_age_gap'], df['po_gender'], df['ins_gender']))\n",
    "df['po_ins_rela'] = df['po_ins_rela'].map(lambda x: which_rela(x[0],x[1],x[2],x[3]))\n",
    "\n",
    "#prepare margin dict\n",
    "margin = margin.drop_duplicates()\n",
    "\n",
    "margin_last_year = margin.groupby(['plan_code','customer_needs']\n",
    "               )['effective_date'].nunique().reset_index().sort_values(by = 'effective_date',ascending = False\n",
    "                                                                      ).drop_duplicates(keep = 'first', \n",
    "                                                                                        subset = ['plan_code'])\n",
    "\n",
    "margin_type_dict = dict(zip(margin_last_year['plan_code'], (margin_last_year['customer_needs'])))\n",
    "\n",
    "\n",
    "margin['nbv_margin_agency'] = margin['nbv_margin_agency'].astype(float)\n",
    "margin_nbv_dict = margin[margin['effective_qtr'].map(lambda x: x[:4]) == str(current_year - 1)\n",
    "                        ].groupby(['plan_code'])['nbv_margin_agency'].mean().to_dict()\n",
    "\n",
    "#prd type and margin\n",
    "df['type'] = df['plan_code'].map(lambda x: margin_type_dict[x] if x in margin_type_dict else np.nan)\n",
    "\n",
    "# nbv and margin\n",
    "df['margin_nbv'] = df['plan_code'].map(lambda x: margin_nbv_dict[x] if x in margin_nbv_dict else np.nan)\n",
    "df['nbv'] = df['adjust_ape'] * df['margin_nbv']\n",
    "\n",
    "# prd cus mix\n",
    "df['prd_cus_mix'] = df['type'] + '_' + df['po_ins_rela']\n",
    "\n",
    " # A/N:not-taken, B:lapsed, R:Rejected\n",
    "df['is_non_taken'] = (df['pol_stat_cd'].isin(['A', 'N'])).astype(int)\n",
    "df['lapsed'] = (df['pol_stat_cd'] == 'B').astype(int)\n",
    "df['Rejected'] = (df['pol_stat_cd'] == 'R').astype(int)\n",
    "\n",
    "df['cvg_eff_week_from_agt_join'] = ((df['cvg_eff_dt'].dt.date - \n",
    "                                     df['agt_join_dt'].dt.date).dt.days/7\n",
    "                                   ).astype(int) + 1\n",
    "\n",
    "df['max_date'] = max_date\n",
    "\n",
    "df = df[(df['max_date']>= df['cvg_eff_dt'])&(df['max_date']>= df['pol_eff_dt'])].reset_index(drop = True)\n",
    "\n",
    "df['last_n_month_eff_cvg'] = (df['cvg_eff_dt'].dt.to_period('M').astype(int) - \n",
    "                              df['max_date'].dt.to_period('M').astype(int)\n",
    "                             ) - 1\n",
    "tier_dict = dict(zip(mdrt['Agt code'], mdrt[' Ranking ']))\n",
    "\n",
    "df['tier'] = df['wa_cd_1'].map(lambda x: tier_dict[x] if x in tier_dict else 'Platinum')\n",
    "df['year_month'] = df['cvg_eff_dt'].dt.to_period('M')\n",
    "\n",
    "mp_level = dict(zip(mp['agt_cd'], mp['level']))\n",
    "df['mp_level'] = df['wa_cd_1'].map(lambda x: mp_level[x] if x in mp_level else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19fc69ff-d7bf-4019-a833-9e3e7dc7a479",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#prepare for other tables\n",
    "#top_leads_needs.columns = [i.split('.')[1] for i in top_leads_needs.columns]\n",
    "\n",
    "sub = df[['pol_num', 'wa_cd_1']].drop_duplicates()\n",
    "pol_agt = dict(zip(sub['pol_num'], sub['wa_cd_1']))\n",
    "\n",
    "sub = df[['cli_num', 'wa_cd_1']].drop_duplicates()\n",
    "cli_agt = dict(zip(sub['cli_num'].astype(int), sub['wa_cd_1']))\n",
    "\n",
    "sub = df[['po_num', 'wa_cd_1']].drop_duplicates()\n",
    "po_agt = dict(zip(sub['po_num'], sub['wa_cd_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab2bf124-2c76-4bd3-9c2e-0051db04ef6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# prepare agt table\n",
    "\n",
    "tagtdm_daily['max_date'] = max_date\n",
    "tagtdm_daily['tenure_mth'] = tagtdm_daily['max_date'].dt.to_period('M').astype(int) - tagtdm_daily['agt_join_dt'].dt.to_period('M').astype(int)\n",
    "agt = tagtdm_daily[['wa_cd_1','agt_nm','rank_code', 'br_code', 'tenure_mth', 'agt_join_dt']]\n",
    "agt = agt[agt['wa_cd_1'].isin(mp['agt_cd'])].reset_index(drop = True)\n",
    "agt['tier'] = agt['wa_cd_1'].map(lambda x: tier_dict[x] if x in tier_dict else 'Platinum')\n",
    "\n",
    "agt.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a86c214-7711-443a-ab2b-252d5212a5e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#prepare aggregate level KPIs\n",
    "\n",
    "#ape\n",
    "f1 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f1.name = 'last_mth_ape'\n",
    "\n",
    "f2 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f2.name = 'last_yr_ape'\n",
    "\n",
    "f3 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f3.name = 'last_3m_ape'\n",
    "\n",
    "f4 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f4.name = 'last_6m_ape'\n",
    "\n",
    "#nbv\n",
    "f5 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['nbv'].sum().fillna(0)\n",
    "f5.name = 'last_mth_nbv'\n",
    "\n",
    "f6 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['nbv'].sum().fillna(0)\n",
    "f6.name = 'last_yr_nbv'\n",
    "\n",
    "f7 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['nbv'].sum().fillna(0)\n",
    "f7.name = 'last_3m_nbv'\n",
    "\n",
    "f8 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['nbv'].sum().fillna(0)\n",
    "f8.name = 'last_6m_nbv'\n",
    "\n",
    "#po\n",
    "f9 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['po_num'].nunique().fillna(0)\n",
    "f9.name = 'last_mth_po'\n",
    "\n",
    "f10 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['po_num'].nunique().fillna(0)\n",
    "f10.name = 'last_yr_po'\n",
    "\n",
    "f11 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['po_num'].nunique().fillna(0)\n",
    "f11.name = 'last_3m_po'\n",
    "\n",
    "f12 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['po_num'].nunique().fillna(0)\n",
    "f12.name = 'last_6m_po'\n",
    "\n",
    "#cus\n",
    "f13 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['cli_num'].nunique().fillna(0)\n",
    "f13.name = 'last_mth_cus'\n",
    "\n",
    "f14 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['cli_num'].nunique().fillna(0)\n",
    "f14.name = 'last_yr_cus'\n",
    "\n",
    "f15 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['cli_num'].nunique().fillna(0)\n",
    "f15.name = 'last_3m_cus'\n",
    "\n",
    "f16 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['cli_num'].nunique().fillna(0)\n",
    "f16.name = 'last_6m_cus'\n",
    "\n",
    "#pol\n",
    "f17 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f17.name = 'last_mth_pol'\n",
    "\n",
    "f18 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f18.name = 'last_yr_pol'\n",
    "\n",
    "f19 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f19.name = 'last_3m_pol'\n",
    "\n",
    "f20 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f20.name = 'last_6m_pol'\n",
    "\n",
    "#not taken pol\n",
    "f21 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['is_non_taken'] == 1)\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f21.name = 'last_mth_NT'\n",
    "\n",
    "f22 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['is_non_taken'] == 1)\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f22.name = 'last_yr_NT'\n",
    "\n",
    "f23 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['is_non_taken'] == 1)\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f23.name = 'last_3m_NT'\n",
    "\n",
    "f24 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['is_non_taken'] == 1)\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f24.name = 'last_6m_NT'\n",
    "\n",
    "#Rejected pol\n",
    "f25 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['Rejected'] == 1)\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f25.name = 'last_mth_rej'\n",
    "\n",
    "f26 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['Rejected'] == 1)\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f26.name = 'last_yr_rej'\n",
    "\n",
    "f27 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['Rejected'] == 1)\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f27.name = 'last_3m_rej'\n",
    "\n",
    "f28 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['Rejected'] == 1)\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f28.name = 'last_6m_rej'\n",
    "\n",
    "#lapse\n",
    "f29 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') == df['max_date'].dt.to_period('M'))&\n",
    "        (df['status'] == 'Lapsed')\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f29.name = 'last_mth_lap'\n",
    "\n",
    "f30 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') <= df['max_date'].dt.to_period('M'))&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') > df['max_date'].dt.to_period('M') - 12)&\n",
    "        (df['status'] == 'Lapsed')\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f30.name = 'last_yr_lap'\n",
    "\n",
    "f31 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') <= df['max_date'].dt.to_period('M'))&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') > df['max_date'].dt.to_period('M') - 3)&\n",
    "        (df['status'] == 'Lapsed')\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f31.name = 'last_3m_lap'\n",
    "\n",
    "f32 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') <= df['max_date'].dt.to_period('M'))&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') > df['max_date'].dt.to_period('M') - 6)&\n",
    "        (df['status'] == 'Lapsed')\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "f32.name = 'last_6m_lap'\n",
    "\n",
    "#prd_type\n",
    "f33 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['type'].nunique().fillna(0)\n",
    "f33.name = 'last_mth_prd'\n",
    "\n",
    "f34 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['type'].nunique().fillna(0)\n",
    "f34.name = 'last_yr_prd'\n",
    "\n",
    "f35 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['type'].nunique().fillna(0)\n",
    "f35.name = 'last_3m_prd'\n",
    "\n",
    "f36 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['type'].nunique().fillna(0)\n",
    "f36.name = 'last_6m_prd'\n",
    "\n",
    "#family member\n",
    "f37 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['po_ins_rela'].nunique().fillna(0)\n",
    "f37.name = 'last_mth_fam'\n",
    "\n",
    "f38 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['po_ins_rela'].nunique().fillna(0)\n",
    "f38.name = 'last_yr_fam'\n",
    "\n",
    "f39 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['po_ins_rela'].nunique().fillna(0)\n",
    "f39.name = 'last_3m_fam'\n",
    "\n",
    "f40 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['po_ins_rela'].nunique().fillna(0)\n",
    "f40.name = 'last_6m_fam'\n",
    "\n",
    "#rider_ape\n",
    "f41 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (df['cvg_typ'] == 'R')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f41.name = 'last_mth_rid'\n",
    "\n",
    "f42 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'R')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f42.name = 'last_yr_rid'\n",
    "\n",
    "f43 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'R')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f43.name = 'last_3m_rid'\n",
    "\n",
    "f44 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['cvg_typ'] == 'R')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f44.name = 'last_6m_rid'\n",
    "\n",
    "#repeat_ape\n",
    "f45 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] == -1)&\n",
    "        (df['repeat_sales'] == 1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f45.name = 'last_mth_rep'\n",
    "\n",
    "f46 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -12)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['repeat_sales'] == 1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f46.name = 'last_yr_rep'\n",
    "\n",
    "f47 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -3)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['repeat_sales'] == 1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f47.name = 'last_3m_rep'\n",
    "\n",
    "f48 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['last_n_month_eff_cvg'] >= -6)&\n",
    "        (df['last_n_month_eff_cvg'] <= -1)&\n",
    "        (df['repeat_sales'] == 1)&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "f48.name = 'last_6m_rep'\n",
    "\n",
    "\n",
    "#avg_pol_size\n",
    "f49 = f1/f17\n",
    "f49.name = 'last_mth_pol_size'\n",
    "\n",
    "f50 = f2/f18\n",
    "f50.name = 'last_yr_pol_size'\n",
    "\n",
    "f51 = f3/f19\n",
    "f51.name = 'last_3m_pol_size'\n",
    "\n",
    "f52 = f4/f20\n",
    "f52.name = 'last_6m_pol_size'\n",
    "\n",
    "#avg_po_size\n",
    "f53 = f1/f9\n",
    "f53.name = 'last_mth_po_size'\n",
    "\n",
    "f54 = f2/f10\n",
    "f54.name = 'last_yr_po_size'\n",
    "\n",
    "f55 = f3/f11\n",
    "f55.name = 'last_3m_po_size'\n",
    "\n",
    "f56 = f4/f12\n",
    "f56.name = 'last_6m_po_size'\n",
    "\n",
    "f57 = (1 - f21/f19).fillna(1)\n",
    "f57.name = 'last_mth_NT_per'\n",
    "\n",
    "f58 = (1 - f22/f19).fillna(1)\n",
    "f58.name = 'last_yr_NT_per'\n",
    "\n",
    "f59 = (1 - f23/f19).fillna(1)\n",
    "f59.name = 'last_3m_NT_per'\n",
    "\n",
    "f60 = (1 - f24/f19).fillna(1)\n",
    "f60.name = 'last_6m_NT_per'\n",
    "\n",
    "f61 = (1 - f25/f19).fillna(1)\n",
    "f61.name = 'last_mth_rej_per'\n",
    "\n",
    "f62 = (1 - f26/f19).fillna(1)\n",
    "f62.name = 'last_yr_rej_per'\n",
    "\n",
    "f63 = (1 - f27/f19).fillna(1)\n",
    "f63.name = 'last_3m_rej_per'\n",
    "\n",
    "f64 = (1 - f28/f19).fillna(1)\n",
    "f64.name = 'last_6m_rej_per'\n",
    "\n",
    "f65 = (1 - f29/f19).fillna(1)\n",
    "f65.name = 'last_mth_lap_per'\n",
    "\n",
    "f66 = (1 - f30/f19).fillna(1)\n",
    "f66.name = 'last_yr_lap_per'\n",
    "\n",
    "f67 = (1 - f31/f19).fillna(1)\n",
    "f67.name = 'last_3m_lap_per'\n",
    "\n",
    "f68 = (1 - f32/f19).fillna(1)\n",
    "f68.name = 'last_6m_lap_per'\n",
    "\n",
    "f = pd.concat([f1,\n",
    "f2,\n",
    "f3,\n",
    "f4,\n",
    "f5,\n",
    "f6,\n",
    "f7,\n",
    "f8,\n",
    "f9,\n",
    "f10,\n",
    "f11,\n",
    "f12,\n",
    "f13,\n",
    "f14,\n",
    "f15,\n",
    "f16,\n",
    "f17,\n",
    "f18,\n",
    "f19,\n",
    "f20,\n",
    "f21,\n",
    "f22,\n",
    "f23,\n",
    "f24,\n",
    "f25,\n",
    "f26,\n",
    "f27,\n",
    "f28,\n",
    "f29,\n",
    "f30,\n",
    "f31,\n",
    "f32,\n",
    "f33,\n",
    "f34,\n",
    "f35,\n",
    "f36,\n",
    "f37,\n",
    "f38,\n",
    "f39,\n",
    "f40,\n",
    "f41,\n",
    "f42,\n",
    "f43,\n",
    "f44,\n",
    "f45,\n",
    "f46,\n",
    "f47,\n",
    "f48,\n",
    "f49,\n",
    "f50,\n",
    "f51,\n",
    "f52,\n",
    "f53,\n",
    "f54,\n",
    "f55,\n",
    "f56,\n",
    "f57,\n",
    "f58,\n",
    "f59,\n",
    "f60,\n",
    "f61,\n",
    "f62,\n",
    "f63,\n",
    "f64,\n",
    "f65,\n",
    "f66,\n",
    "f67,\n",
    "f68\n",
    "],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ccfa503-070c-4934-8cc3-e88d4e0de2c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# step 4. Validate and double check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4bbf93d-a4dd-455f-a896-071b3da8f519",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f1.sum())\n",
    "print(f2.sum())\n",
    "print(f3.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb2d9ea-43aa-4a6e-b3c4-0d262dde8e92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f1.sum())\n",
    "print(f2.sum())\n",
    "print(f3.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "932b6c2f-3a5a-4219-a6a4-ffe02b1b5922",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "               (df['last_n_month_eff_cvg'] >= -12)&\n",
    "               (df['last_n_month_eff_cvg'] <= -1)&\n",
    "                (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "               ]['cvg_eff_dt'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d632127a-93f8-4045-b185-5596012079de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 5. generate KPIs for output tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b0ca551-144f-458d-801b-b0a3f4261b14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# preprare benchmark KPIs of monthly ape and prd mix\n",
    "avg_sales = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "               (df['last_n_month_eff_cvg'] >= -12)&\n",
    "               (df['last_n_month_eff_cvg'] <= -1)&\n",
    "                (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "               ].groupby(['wa_cd_1','year_month'])['adjust_ape'].sum().unstack().fillna(0).astype(int).stack().reset_index().rename(columns= {0:'ape'})\n",
    "avg_sales = avg_sales.groupby(['year_month']).mean().astype(int).reset_index()\n",
    "avg_sales.columns = ['date', 'avg_ape_tier']\n",
    "avg_sales['current_tier'] = 'Platinum'\n",
    "\n",
    "mth_sales = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "               (df['last_n_month_eff_cvg'] >= -12)&\n",
    "               (df['last_n_month_eff_cvg'] <= -1)&\n",
    "                (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "               ].groupby(['wa_cd_1','year_month'])['adjust_ape'].sum().unstack().fillna(0).astype(int).stack().reset_index()\n",
    "mth_sales.columns = ['agt_cd', 'date', 'avg_ape_agt']\n",
    "mth_sales['current_tier'] = 'Platinum'\n",
    "mth_sales = pd.merge(mth_sales, avg_sales, on = ['current_tier','date'], how = 'left')\n",
    "\n",
    "avg_prd = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "               (df['last_n_month_eff_cvg'] >= -12)&\n",
    "               (df['last_n_month_eff_cvg'] <= -1)&\n",
    "               (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "               ].groupby(['type'])['adjust_ape'].sum().fillna(0).astype(int).reset_index()\n",
    "avg_prd.columns = ['prd_type', 'sum_ape_tier']\n",
    "avg_prd['current_tier'] = 'Platinum'\n",
    "\n",
    "mth_prd = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "               (df['last_n_month_eff_cvg'] >= -12)&\n",
    "               (df['last_n_month_eff_cvg'] <= -1)&\n",
    "              (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "               ].groupby(['wa_cd_1','type'])['adjust_ape'].sum().unstack().fillna(0).astype(int).stack().reset_index()\n",
    "mth_prd.columns = ['agt_cd', 'prd_type', 'sum_ape_agt']\n",
    "mth_prd['current_tier'] = 'Platinum'\n",
    "mth_prd = pd.merge(mth_prd, avg_prd, on = ['current_tier','prd_type'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e5af39-a598-4634-b1e5-28053c59b4d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# prepare claim KPIs\n",
    "tclaim['agt_cd'] = tclaim['pol_num'].map(lambda x: pol_agt[x] if x in pol_agt else np.nan)\n",
    "tclaim['clm_aprov_amt'] = tclaim['clm_aprov_amt']*1000\n",
    "tclaim['adj_aprov_amt'] = tclaim['adj_aprov_amt']*1000\n",
    "tclaim['clm_prvd_amt'] = tclaim['clm_prvd_amt']*1000\n",
    "\n",
    "y3 = tclaim[(tclaim['clm_recv_dt'] <= max_date)\n",
    "            &(tclaim['clm_recv_dt'] >= max_date - pd.offsets.DateOffset(years=3))\n",
    "            ].groupby(['agt_cd'])['clm_id'].nunique()\n",
    "\n",
    "y3.name = 'claim_cnt_last_3_yr'\n",
    "\n",
    "y3_amt = tclaim[(tclaim['clm_recv_dt'] <= max_date)\n",
    "                &(tclaim['clm_recv_dt'] >= max_date - pd.offsets.DateOffset(years=3))\n",
    "               ].groupby(['agt_cd'])['clm_prvd_amt'].sum()\n",
    "\n",
    "y3_amt.name = 'claim_amt_last_3_yr'\n",
    "\n",
    "y3_appr = tclaim[(tclaim['clm_recv_dt'] <= max_date)\n",
    "                &(tclaim['clm_recv_dt'] >= max_date - pd.offsets.DateOffset(years=3))\n",
    "                &(tclaim['clm_stat_code'] == 'A')\n",
    "               ].groupby(['agt_cd'])['clm_id'].nunique()\n",
    "\n",
    "y3_appr.name = 'claim_appr_cnt_last_3_yr'\n",
    "\n",
    "y3_appr_amt = tclaim[(tclaim['clm_recv_dt'] <= max_date)\n",
    "                   &(tclaim['clm_recv_dt'] >= max_date - pd.offsets.DateOffset(years=3))\n",
    "                    &(tclaim['clm_stat_code'] == 'A')\n",
    "                ].groupby(['agt_cd'])['clm_aprov_amt'].sum()\n",
    "\n",
    "y3_appr_amt.name = 'claim_appr_amt_last_3_yr'\n",
    "\n",
    "y1_wip = tclaim[(tclaim['clm_recv_dt'] <= max_date)\n",
    "                &(tclaim['clm_recv_dt'] >= max_date - pd.offsets.DateOffset(years=1))\n",
    "                &(tclaim['clm_stat_code'] == 'I')\n",
    "               ].groupby(['agt_cd'])['clm_id'].nunique()\n",
    "\n",
    "y1_wip.name = 'claim_wip_last_1_yr'\n",
    "\n",
    "y3_appr_rate = y3_appr/y3\n",
    "y3_appr_rate.name = 'claim_appr_rate_last_3_yr'\n",
    "\n",
    "clm = pd.concat([y3, y3_amt, y3_appr, y3_appr_amt, y1_wip], axis = 1).fillna(0).astype(int)\n",
    "clm['claim_appr_rate_last_3_yr'] = clm['claim_appr_cnt_last_3_yr']/clm['claim_cnt_last_3_yr']\n",
    "\n",
    "clm['chart'] = '3yr_claim'\n",
    "clm['chart_kpi'] = 'pol_cnt_or_amt'\n",
    "\n",
    "clm = clm.reset_index()\n",
    "clm.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5abe6010-4eed-455a-b62d-65a0c322dd51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#prepare persistency KPIs\n",
    "pol_cnt = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique()\n",
    "\n",
    "pol_cnt.name = 'all_pol_cnt'\n",
    "\n",
    "lap14 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') <= df['pol_eff_dt'].dt.to_period('M') + 14)&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') >= df['pol_eff_dt'].dt.to_period('M'))&\n",
    "        (df['status'] == 'Lapsed')\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique()\n",
    "\n",
    "lap14.name = 'lap_14m_pol'\n",
    "\n",
    "lap26 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') <= df['pol_eff_dt'].dt.to_period('M') + 26)&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') >= df['pol_eff_dt'].dt.to_period('M'))&\n",
    "        (df['status'] == 'Lapsed')\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique()\n",
    "       \n",
    "lap26.name = 'lap_26m_pol'\n",
    "\n",
    "lap20 = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "        (df['cvg_typ'] == 'B')&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') <= df['pol_eff_dt'].dt.to_period('M') + 20)&\n",
    "        (df['pol_trmn_dt'].dt.to_period('M') >= df['pol_eff_dt'].dt.to_period('M'))&\n",
    "        (df['status'] == 'Lapsed')\n",
    "       ].groupby(['wa_cd_1'])['pol_num'].nunique()\n",
    "       \n",
    "lap20.name = 'lap_20m_pol'\n",
    "\n",
    "last_yr_pol = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                (df['last_n_month_eff_cvg'] >= -12)&\n",
    "                (df['last_n_month_eff_cvg'] <= -1)&\n",
    "                (df['cvg_typ'] == 'B')\n",
    "                ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "last_yr_pol.name = 'last_yr_pol'\n",
    "\n",
    "per = pd.concat([pol_cnt, lap14, lap26, lap20, last_yr_pol, f22], axis = 1).fillna(0).astype(int)\n",
    "\n",
    "per['14m_per'] = 1 - per['lap_14m_pol'] / per['all_pol_cnt']\n",
    "per['20m_per'] = 1 - per['lap_20m_pol'] / per['all_pol_cnt']\n",
    "per['26m_per'] = 1 - per['lap_26m_pol'] / per['all_pol_cnt']\n",
    "per['12M_NT_rate'] = (per['last_yr_NT'] / per['last_yr_pol']).fillna(0)\n",
    "del per['last_yr_pol']\n",
    "del per['last_yr_NT']\n",
    "per['chart'] = 'lapse_kpi'\n",
    "per['chart_kpi'] = 'pol_cnt'\n",
    "\n",
    "per = per.reset_index().rename(columns = {'wa_cd_1':'agt_cd'})\n",
    "\n",
    "persis_raw_dict = dict(zip(m19_per_vn['agt_cd'], m19_per_vn['m19_per'].astype(int)/100))\n",
    "per['19m_per_from_VN'] = per['agt_cd'].map(lambda x: persis_raw_dict[x])\n",
    "\n",
    "per.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "441d3a72-3715-4fca-81c6-b243a1079612",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#from lapse model > filter by snapshot please\n",
    "lapse['agt_cd'] = lapse['pol_num'].map(lambda x: pol_agt[x] if x in pol_agt else np.nan)\n",
    "lapse = lapse[(~lapse['agt_cd'].isnull())&(lapse['month_snapshot'] == snapshot)].reset_index(drop = True)\n",
    "\n",
    "pol_eff_dict = dict(zip(df['pol_num'], df['pol_eff_dt']))\n",
    "pol_po_dict = dict(zip(df['pol_num'], df['po_num']))\n",
    "pd_to_dict = dict(zip(df['pol_num'], df['pd_to_dt']))\n",
    "pol_prd_dict = dict(zip(df[df['cvg_typ'] == 'B']['pol_num'], df[df['cvg_typ'] == 'B']['type']))\n",
    "\n",
    "pmt_mode_map = dict({1:'monthly', 3:'quarterly', 6:'half-yearly', 12:'yearly'})\n",
    "df['pmt_mode_map'] = df['pmt_mode'].astype(int).map(lambda x: pmt_mode_map[x])\n",
    "pol_pmt_dict = dict(zip(df['pol_num'], df['pmt_mode_map']))\n",
    "\n",
    "lapse['pol_eff_dt'] = lapse['pol_num'].map(lambda x: pol_eff_dict[x] if x in pol_eff_dict else np.nan)\n",
    "lapse['po_num'] = lapse['pol_num'].map(lambda x: pol_po_dict[x] if x in pol_po_dict else np.nan)\n",
    "lapse['type'] = lapse['pol_num'].map(lambda x: pol_prd_dict[x] if x in pol_prd_dict else np.nan)\n",
    "lapse['pmt_mode'] = lapse['pol_num'].map(lambda x: pol_pmt_dict[x] if x in pol_pmt_dict else np.nan)\n",
    "lapse['cli_nm'] = lapse['po_num'].map(lambda x: cli_num_name_dict[str(x)] if str(x) in cli_num_name_dict else np.nan)\n",
    "lapse['pd_to_dt'] = lapse['pol_num'].map(lambda x: pd_to_dict[x] if x in pd_to_dict else np.nan)\n",
    "\n",
    "# lapse model changed to add 1 month buffer\n",
    "lps = lapse[(lapse['pd_to_dt'].dt.year >= int(max_date_str[:4]))&(lapse['lapse_score']>=0.05)] \n",
    "lps = lps.sort_values('lapse_score',ascending = False).groupby('agt_cd').head(10)\n",
    "lps = lps[['agt_cd','pol_num','po_num','cli_nm','pmt_mode','lapse_score','pol_eff_dt','pd_to_dt']]\n",
    "lps.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f10fde86-a464-4e51-9333-d26194f32635",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lapse_diag = lps.sort_values('lapse_score',ascending = False).groupby('agt_cd').head(3)\n",
    "lapse_diag = lapse_diag.groupby(['agt_cd'])['pol_num'].apply(list).reset_index()\n",
    "lapse_diag['pol_num'] = lapse_diag['pol_num'].map(lambda x: list(set(x)))\n",
    "lapse_diag.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d80df60-77a9-44e8-a015-d760e4a11b25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# leads models output\n",
    "leads_existing_model = leads_existing_model[leads_existing_model['image_date'] == max_date_str]\n",
    "leads_existing_model['po_num'] = leads_existing_model['po_num'].astype(int)\n",
    "leads_existing_model['agt_cd'] = leads_existing_model['po_num'].map(lambda x: po_agt[x] if x in po_agt else np.nan)\n",
    "leads_existing_model = leads_existing_model[leads_existing_model['agt_cd'].isin(agt['wa_cd_1'])]\n",
    "leads_existing_model = leads_existing_model.sort_values('p_1',ascending = False).groupby('agt_cd').head(10)\n",
    "\n",
    "multiclass.columns = [i.replace('rep_purchase_comb_','') if 'rep_purchase_comb_' in i else i for i in multiclass.columns]\n",
    "multiclass.columns = [i.replace('_PREDICTION','') if '_PREDICTION' in i else i for i in multiclass.columns]\n",
    "multiclass = multiclass[multiclass['DEPLOYMENT_APPROVAL_STATUS']=='APPROVED']\n",
    "\n",
    "multiclass['which_prd'] = multiclass[['health_base','inv_base','health_rider','riders']].idxmax(axis=1)\n",
    "multiclass['inv_base'] = multiclass['which_prd'].map(lambda x: '*' if x == 'inv_base' else '')\n",
    "#use 0.1 as cut off as the model use softmax as activation function\n",
    "multiclass['health_base'] = multiclass['health_base'].map(lambda x: '*' if x > 0.1 else '')\n",
    "multiclass['riders'] = multiclass['riders'].map(lambda x: '*' if x > 0.1 else '')\n",
    "multiclass['health_rider'] = multiclass['health_rider'].map(lambda x: '*' if x > 0.1 else '')\n",
    "multiclass.head(2)\n",
    "\n",
    "nm = pd.merge(leads_existing_model, multiclass, on = 'po_num', how = 'left')\n",
    "nm = nm[~nm['which_prd'].isnull()]\n",
    "nm['pol_num'] = nm['po_num'].astype(str).map(lambda x: po_pol_dict[x] if x in po_pol_dict else np.nan)\n",
    "nm = nm[~nm['pol_num'].isnull()]\n",
    "nm = nm.sort_values('p_1',ascending = False).groupby('agt_cd').head(10)\n",
    "nm = nm[['agt_cd','po_num','pol_num','health_base','inv_base','health_rider','riders','p_1']]\n",
    "nm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7102a0e6-4c0c-44e5-8507-54447b466f8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nm_diag = nm.sort_values('p_1',ascending = False).groupby('agt_cd').head(3)\n",
    "nm_diag = nm_diag.groupby(['agt_cd'])['pol_num'].apply(list).reset_index()\n",
    "#nm_diag = nm_diag.rename(columns = {'po_num':'cli_num'})\n",
    "nm_diag.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f30afd0-49e2-48bc-9598-9cd36fc81635",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mth_allowance.columns = [i.strip() for i in mth_allowance.columns]\n",
    "#mth_allowance['monthly_allowance'] = mth_allowance['monthly_allowance'].map(lambda x: int(x.replace(',', ''))*1000)\n",
    "mth_allowance['monthly_allowance'] = mth_allowance['monthly_allowance'].fillna(0).map(lambda x: int(x)*1000)\n",
    "mth_allowance['qualify_date'] = pd.to_datetime(mth_allowance['qualify_date'], format='%Y%m').dt.to_period('M')\n",
    "\n",
    "mth_allowance_dict = dict(zip(mth_allowance['agt_cd'], mth_allowance['monthly_allowance']))\n",
    "qualify_date_dict = dict(zip(mth_allowance['agt_cd'], mth_allowance['qualify_date']))\n",
    "agt['monthly_allowance'] = agt['wa_cd_1'].map(lambda x: mth_allowance_dict[x] if x in mth_allowance_dict else np.nan)\n",
    "agt['qualify_date'] = agt['wa_cd_1'].map(lambda x: qualify_date_dict[x] if x in qualify_date_dict else pd.NaT)\n",
    "\n",
    "agt['monthly_allowance'] = agt['monthly_allowance'].fillna(0)\n",
    "agt['qualify_date'] = agt['qualify_date'].fillna(agt['qualify_date'].max())\n",
    "agt['next_qualify_check'] = agt['qualify_date'] + 11\n",
    "agt['qualify_date'] = agt['qualify_date'].astype(str)\n",
    "agt['next_qualify_check'] = agt['next_qualify_check'].astype(str)\n",
    "agt.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9673649-01ec-4153-b804-71906818f0d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#page 1 KPIs\n",
    "page1 = agt.rename(columns = {'wa_cd_1':'agt_cd'})\n",
    "page1['report_month'] = mth_partition\n",
    "page1['qualify_tenure'] = (pd.to_datetime(page1['report_month']).dt.to_period('M').astype(int) - \n",
    "                           pd.to_datetime(page1['qualify_date']).dt.to_period('M').astype(int)) + 1\n",
    "next_tier = dict({'Platinum': 'MDRT', 'MDRT': 'COT', 'COT': 'TOT', 'TOT': 'TOT'})\n",
    "ape_all_agt = df[df['year_month'].astype(str) == mth_partition].groupby(['wa_cd_1'])['adjust_ape'].sum()\n",
    "last_mth_ape_dict = ape_all_agt.to_dict()\n",
    "last_mth_ape_rank_dict = ape_all_agt.rank(ascending=False).astype(int).to_dict()\n",
    "page1['last_mth_ape'] = page1['agt_cd'].map(lambda x: last_mth_ape_dict[x] if x in last_mth_ape_dict else 0)\n",
    "page1['rank_of_last_mth_ape'] = page1['agt_cd'].map(lambda x: last_mth_ape_rank_dict[x] if x in last_mth_ape_rank_dict else np.nan)\n",
    "page1['next_tier'] = page1['tier'].map(lambda x: next_tier[x])\n",
    "page1['next_tier_benchmark'] = page1['next_tier'].map(lambda x: ape_benchmark[x])\n",
    "page1['tenure_ym'] = page1['tenure_mth'].map(lambda x: str(divmod(x, 12)[0]) + ' y ' + str(divmod(x, 12)[1]) + ' m')\n",
    "page1['monthly_allowance_rank'] = (agt.shape[0] - page1['monthly_allowance'].rank(axis=0, ascending=False).astype(int))/agt.shape[0]\n",
    "page1['monthly_allowance_rank'] = page1['monthly_allowance_rank'].map(lambda x: 0.99 if x >= 0.99 else x)\n",
    "rank_min_allowance = page1['monthly_allowance_rank'].min()\n",
    "page1['monthly_allowance_rank'] = page1['monthly_allowance_rank'].map(lambda x: 0 if x == rank_min_allowance else x)\n",
    "page1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15cd5c4-449a-4947-b94a-4b41e1d6e525",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#page 2\n",
    "page2 = pd.concat([f.fillna(0)[['last_3m_pol','last_3m_ape','last_3m_lap','last_3m_rep','last_3m_rid','last_3m_po']], \n",
    "                   f[['last_3m_pol_size','last_3m_po_size']]], axis = 1).reset_index()\n",
    "\n",
    "page2 = page2.rename(columns = {'wa_cd_1':'agt_cd'})\n",
    "page2['current_tier'] = page2['agt_cd'].map(lambda x: tier_dict[x] if x in tier_dict else 'Platinum')\n",
    "page2['tier'] = page2['agt_cd'].map(lambda x: tier_dict[x] if x in tier_dict else 'Platinum')\n",
    "page2['next_tier'] = page2['tier'].map(lambda x: next_tier[x])\n",
    "\n",
    "p2_avg = page2.set_index('agt_cd').groupby(['tier']).mean().unstack().reset_index().groupby(['tier','level_0'])[0].max().unstack()\n",
    "p2_avg['last_3m_po_size'] = (page2.set_index('agt_cd').groupby(['tier'])['last_3m_ape'].sum())/(page2.set_index('agt_cd').groupby(['tier'])['last_3m_po'].sum())\n",
    "p2_avg['last_3m_pol_size'] = ((page2.set_index('agt_cd').groupby(['tier'])['last_3m_ape'].sum() - page2.set_index('agt_cd').groupby(['tier'])['last_3m_rid'].sum())\n",
    "                              /(page2.set_index('agt_cd').groupby(['tier'])['last_3m_po'].sum()))\n",
    "\n",
    "p2_current = p2_avg.copy()\n",
    "p2_current.columns = ['current_'+i for i in p2_current.columns]\n",
    "p2_current = p2_current.reset_index().rename(columns = {'tier': 'current_tier'})\n",
    "p2_next = p2_avg.copy()\n",
    "p2_next.columns = ['next_'+i for i in p2_next.columns]\n",
    "p2_next = p2_next.reset_index().rename(columns = {'tier': 'next_tier'})\n",
    "\n",
    "page2['Platinum'] = 'Platinum'\n",
    "p2_plati = page2.set_index('agt_cd').groupby(['Platinum']).mean().unstack().reset_index().groupby(['Platinum','level_0'])[0].max().unstack()\n",
    "p2_plati['last_3m_po_size'] = (page2.set_index('agt_cd').groupby(['Platinum'])['last_3m_ape'].sum())/(page2.set_index('agt_cd').groupby(['Platinum'])['last_3m_po'].sum())\n",
    "p2_plati['last_3m_pol_size'] = ((page2.set_index('agt_cd').groupby(['Platinum'])['last_3m_ape'].sum() - \n",
    "                                 page2.set_index('agt_cd').groupby(['Platinum'])['last_3m_rid'].sum())\n",
    "                              /(page2.set_index('agt_cd').groupby(['Platinum'])['last_3m_po'].sum()))\n",
    "p2_plati.columns = ['platinum_'+i for i in p2_plati.columns]\n",
    "p2_plati = p2_plati.reset_index()\n",
    "\n",
    "page2_all = pd.merge(page2, p2_current, on = 'current_tier', how = 'left' )\n",
    "page2_all = pd.merge(page2_all, p2_next, on = 'next_tier', how = 'left' )\n",
    "page2_all = pd.merge(page2_all, p2_plati, on = 'Platinum', how = 'left' )\n",
    "page2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c5139c7-7dc4-426a-9ffa-c83f39628f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#prepare for diagnosing\n",
    "avg_rid_per = f43.sum()/f3.sum()\n",
    "avg_rep_per = f47.sum()/f3.sum()\n",
    "avg_case_size = f51.mean()\n",
    "avg_fami_mbr = f39.median()\n",
    "avg_14m_per = per['14m_per'].median()\n",
    "\n",
    "def diagnose_recommend(x, avg_rid_per, avg_rep_per, avg_case_size, avg_fami_mbr, avg_14m_per):\n",
    "    out = []\n",
    "    if x[6]/3 >= 600000000/12:\n",
    "        out.append(\"Congratulations!\") \n",
    "        out.append(\"You are one of Manulife's top Manulife Pro Platinum Agents - this means you are the best of the best!\")\n",
    "        out.append(\"You are well on track to requalify for Platinum status at the next assessment date on \" + x[9] + \".\")\n",
    "        out.append(\"Keep up the momentum to get more Manulife Pro Monthly Allowance each month! Here are some further customer sales opportunities for you to take action.\")\n",
    "    elif (x[6]/3 > 0)&(x[7] > 0):\n",
    "        out.append(\"Your sales performance in the last 3 months seems to be below your potential - but don't worry, we are here to support you! Here are some ideas:\")\n",
    "        if (x[0] <= avg_rid_per - 0.1)&(len(out) < 4):\n",
    "            out.append(\"Sell more riders! You sold \" + str(int(x[0]*100)) + \"% riders, vs \" + str(int(avg_rid_per*100)) + \"% for other Platinum agents.\")\n",
    "        if (x[1] <= avg_rep_per - 0.1)&(len(out) < 4):\n",
    "            out.append(\"Cross sell to your existing customers! You sold \" + str(int(x[1]*100)) + \"% to existing customers, vs \" + str(int(avg_rep_per*100)) + \"% for other Platinum agents.\")\n",
    "        if (x[3] <= avg_case_size*0.7)&(len(out) < 4):\n",
    "            out.append(\"Consider to grow your HNW customer base! Your average case size is \" + str(int(x[3]/100000)/10) + \"M, vs \" + str(int(avg_case_size/1000000)) + \"M for other Platinum agents.\")\n",
    "        if (x[4] < avg_fami_mbr)&(len(out) < 4):\n",
    "            out.append(\"Try to sell to your customers family members! You sold to \" + str(int(x[4])) + \" types of family members, vs \" + str(int(avg_fami_mbr)) + \" for other Platinum agents.\")\n",
    "        if (x[2] <= avg_14m_per - 0.1)&(len(out) < 4):\n",
    "            out.append(\"Improve your sales quality! \" + str(int((1-x[2])*100)) + \"% of your policy lapsed after first year, vs \" + str(int((1-avg_14m_per)*100)) + \"% for other Platinum agents.\")\n",
    "        if len(out) < 4:\n",
    "            out.append(\"Bring this report to discuss with your sales manager or other mentors to help you get back in the game.\")\n",
    "        if len(out) < 4:\n",
    "            out.append(\"We also have a lot of practical learning and development materials on Manuacademy for you to explore!\")\n",
    "        if len(out) < 4:\n",
    "            out.append(\"We look forward to seeing you bounce back!\")\n",
    "    else:\n",
    "        out.append(\"Hi \" + x[10] + \", where have you been? We've missed you here at Manulife and we would love to see you back!\") \n",
    "        out.append(\"As a Manulife Pro Platinum Agent, you are recognized as our privileged group of top agents.\")\n",
    "        out.append(\"Please reach out to your sales manager to discuss how we can help you get back into the game.\")\n",
    "        out.append(\"We look forward to seeing you bounce back!\")\n",
    "    return out\n",
    "\n",
    "rec = pd.concat([agt.set_index('wa_cd_1')['tier'], \n",
    "                (f.fillna(0)['last_3m_rid'] / f['last_3m_ape']),\n",
    "                (f.fillna(0)['last_6m_rep'] / f['last_6m_ape']),\n",
    "                per.set_index(['agt_cd'])['14m_per'],\n",
    "                f['last_6m_pol_size'],\n",
    "                f['last_6m_fam'],\n",
    "                f['last_6m_prd'],\n",
    "                f.fillna(0)['last_3m_ape'],\n",
    "                f.fillna(0)['last_3m_pol'],\n",
    "                f.fillna(0)['last_yr_pol_size'],\n",
    "                agt.set_index('wa_cd_1')['next_qualify_check'],\n",
    "                agt.set_index('wa_cd_1')['agt_nm']\n",
    "                ], axis = 1)\n",
    "rec.columns = ['level', 'rid','rep','14m_per','last_6m_pol_size','last_6m_fam','last_6m_prd','last_3m_ape','last_3m_pol','last_yr_pol_size',\n",
    "               'next_qualify_check', 'agt_name']\n",
    "rec['zip'] = list(zip(rec['rid'],\n",
    "                      rec['rep'],\n",
    "                      rec['14m_per'],\n",
    "                      rec['last_6m_pol_size'],\n",
    "                      rec['last_6m_fam'],\n",
    "                      rec['last_6m_prd'],\n",
    "                      rec['last_3m_ape'],\n",
    "                      rec['last_3m_pol'],\n",
    "                      rec['last_yr_pol_size'],\n",
    "                      rec['next_qualify_check'],\n",
    "                      rec['agt_name']\n",
    "                      ))\n",
    "rec['diag_list'] = rec['zip'].map(lambda x: diagnose_recommend(x, avg_rid_per, avg_rep_per, avg_case_size, avg_fami_mbr, avg_14m_per))\n",
    "rec['diag_0'] = rec['diag_list'].map(lambda x: x[0])\n",
    "rec['diag_1'] = rec['diag_list'].map(lambda x: x[1])\n",
    "rec['diag_2'] = rec['diag_list'].map(lambda x: x[2])\n",
    "rec['diag_3'] = rec['diag_list'].map(lambda x: x[3])\n",
    "rec = rec.reset_index().rename(columns = {'index':'agt_cd'})\n",
    "rec.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf2003ab-3a6e-431f-a0bf-cc539f0bc0d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "qualify_date_mth = dict(zip(agt['wa_cd_1'], pd.to_datetime(agt['qualify_date']).dt.to_period('M')))\n",
    "max_qualify_date = pd.to_datetime(agt['qualify_date']).dt.to_period('M').max()\n",
    "df['qualify_date'] = df['wa_cd_1'].map(lambda x: qualify_date_mth[x] if x in qualify_date_mth else max_qualify_date)\n",
    "\n",
    "ape_this_year = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                   (df['cvg_eff_dt'].dt.year == max_date.year)&\n",
    "                   (df['cvg_eff_dt'] <= max_date)&\n",
    "                   (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "                   ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "ape_this_year.name = 'ape_this_year'\n",
    "\n",
    "ape_since_qualify = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                        (df['cvg_eff_dt'].dt.to_period('M') >= df['qualify_date'])&\n",
    "                        (df['cvg_eff_dt'] <= max_date)&\n",
    "                         (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "                      ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0)\n",
    "ape_since_qualify.name = 'ape_since_qualify'\n",
    "\n",
    "pol_since_qualify = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                        (df['cvg_eff_dt'].dt.to_period('M') >= df['qualify_date'])&\n",
    "                        (df['cvg_eff_dt'] <= max_date)&\n",
    "                         (~df['pol_stat_cd'].isin(['A','N','R']))&\n",
    "                        (df['cvg_typ'] == 'B')\n",
    "                      ].groupby(['wa_cd_1'])['pol_num'].nunique().fillna(0)\n",
    "pol_since_qualify.name = 'pol_since_qualify'\n",
    "\n",
    "active_month = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                        (df['cvg_eff_dt'].dt.to_period('M') >= df['qualify_date'])&\n",
    "                        (df['cvg_eff_dt'] <= max_date)&\n",
    "                         (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "                      ].groupby(['wa_cd_1'])['last_n_month_eff_cvg'].nunique().fillna(0)\n",
    "active_month.name = 'active_month'\n",
    "\n",
    "total_custm = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                 (df['cvg_eff_dt'] <= max_date)&\n",
    "                  (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "                  ].groupby(['wa_cd_1'])['po_num'].nunique()\n",
    "total_custm.name = 'total_custm'\n",
    "\n",
    "best_month = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                (df['cvg_eff_dt'] <= max_date)&\n",
    "                  (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "                  ].groupby(['wa_cd_1', 'cvg_eff_yr_mth'])['adjust_ape'].sum().reset_index().groupby(['wa_cd_1'])['adjust_ape'].max()\n",
    "best_month.name = 'best_month'\n",
    "\n",
    "agt_mth_sales = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                  (~df['pol_stat_cd'].isin(['A','N','R']))&\n",
    "                  (df['cvg_eff_dt'] <= max_date)\n",
    "                  ].groupby(['wa_cd_1', 'cvg_eff_yr_mth'])['adjust_ape'].sum().reset_index()\n",
    "which_month = agt_mth_sales.sort_values('adjust_ape',ascending = False).groupby('wa_cd_1').head(1).set_index('wa_cd_1').rename(columns={'cvg_eff_yr_mth':'which_month_max', 'adjust_ape':'max_mth_ape'})\n",
    "\n",
    "best_case = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "               (df['cvg_eff_dt'] <= max_date)&\n",
    "                  (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "                  ].groupby(['wa_cd_1', 'pol_num'])['adjust_ape'].sum().reset_index().groupby(['wa_cd_1'])['adjust_ape'].max()\n",
    "best_case.name = 'best_case'\n",
    "\n",
    "active_custm = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "                  (df['pol_stat_cd'] == '1')&\n",
    "                  (df['cvg_eff_dt'] <= max_date)&\n",
    "                  (df['pol_trmn_dt'].isnull())\n",
    "                  ].groupby(['wa_cd_1'])['po_num'].nunique()\n",
    "active_custm.name = 'active_custm'\n",
    "\n",
    "total_ape = df[(df['wa_cd_1'].isin(agt['wa_cd_1']))&\n",
    "               (df['cvg_eff_dt'] <= max_date)&\n",
    "                  (~df['pol_stat_cd'].isin(['A','N','R']))\n",
    "                  ].groupby(['wa_cd_1'])['adjust_ape'].sum()\n",
    "total_ape.name = 'total_ape'\n",
    "\n",
    "dash = pd.concat([agt.set_index('wa_cd_1')[['agt_nm','agt_join_dt','tier']],\n",
    "                  ape_since_qualify, pol_since_qualify, active_month,\n",
    "                  total_custm, best_month, best_case, active_custm, total_ape,\n",
    "                  which_month, ape_this_year], axis = 1)\n",
    "\n",
    "dash['ape_since_qualify'] = dash['ape_since_qualify'].fillna(0).astype(int)\n",
    "dash['pol_since_qualify'] = dash['pol_since_qualify'].fillna(0).astype(int)\n",
    "dash['active_month'] = dash['active_month'].fillna(0).astype(int)\n",
    "\n",
    "dash['mp_link_url'] = mp_link_url\n",
    "\n",
    "dash['qualify_ape_min'] = 0\n",
    "dash['qualify_ape_target'] = 600000000\n",
    "dash['qualify_ape_max'] = 600000000\n",
    "\n",
    "dash['qualify_pol_min'] = 0\n",
    "dash['qualify_pol_target'] = 30\n",
    "dash['qualify_pol_max'] = 30\n",
    "\n",
    "dash['qualify_act_mth_min'] = 0\n",
    "dash['qualify_act_target'] = 6\n",
    "dash['qualify_act_max'] = 12\n",
    "\n",
    "dash['next_tier'] = dash['tier'].map(lambda x: next_tier[x])\n",
    "dash['next_tier_benchmark'] = dash['next_tier'].map(lambda x: ape_benchmark[x])\n",
    "dash['gap_to_next_tier'] = dash['next_tier_benchmark'] - dash['ape_this_year'].fillna(0)\n",
    "dash['gap_to_next_tier'] = dash['gap_to_next_tier'].map(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "dash = dash.reset_index().rename(columns = {'wa_cd_1': 'agt_cd'})\n",
    "dash.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "458e792c-16dc-45c0-8b32-2024716f554a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fyp_rank = df[(df['last_n_month_eff_cvg'] == -1)\n",
    "             ].groupby(['wa_cd_1'])['adjust_ape'].sum().fillna(0).rank(axis=0, ascending=False, method = 'min').astype(int)\n",
    "fyp_rank = fyp_rank.reset_index()\n",
    "fyp_rank.columns = ['agt_cd', 'rank_fyp_last_mth']\n",
    "fyp_rank['total_inforce_agt'] = tagtdm_daily.shape[0]\n",
    "fyp_rank['rank_per_fyp_last_mth'] = fyp_rank['rank_fyp_last_mth']/fyp_rank['total_inforce_agt']\n",
    "\n",
    "fyp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b39d709e-0db7-4f37-b449-49c5462b385c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select = mp[['agt_cd']].rename(columns = {'agt_cd':'agt'})\n",
    "select['title_month'] = max_date + timedelta(days = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "561edd99-45fa-4518-8582-733d9865497b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select['report_month'] = mth_partition\n",
    "page1['report_month'] = mth_partition\n",
    "nm['report_month'] = mth_partition\n",
    "nm_diag['report_month'] = mth_partition\n",
    "lps['report_month'] = mth_partition\n",
    "lapse_diag['report_month'] = mth_partition\n",
    "page2_all['report_month'] = mth_partition\n",
    "mth_sales['report_month'] = mth_partition\n",
    "mth_prd['report_month'] = mth_partition\n",
    "clm['report_month'] = mth_partition\n",
    "per['report_month'] = mth_partition\n",
    "fyp_rank['report_month'] = mth_partition\n",
    "rec['report_month'] = mth_partition\n",
    "dash['report_month'] = mth_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55da1fa6-bdaf-463a-b8dc-91a580c9b9f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select.to_csv(f'{out_path}{snapshot}/select.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], page1, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_page1.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], nm, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_needs.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], nm_diag, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_needs_diag.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], lps, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_lapse.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], lapse_diag, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_lapse_diag.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], page2_all, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_page2.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], mth_sales, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_mth_sales.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], mth_prd, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_prd_mix.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], clm, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_claim.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], per, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_persis.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], fyp_rank, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_rank.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], rec, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_recommend.csv', index = False)\n",
    "pd.merge(mp[['agt_cd']], dash, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_dashboard.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f014b290-cbe9-47b0-abd4-49aee0ff7cf9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# for VN version recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dc86cec-e766-4adb-8ace-35449bc90704",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "avg_rid_per = f43.sum()/f3.sum()\n",
    "avg_rep_per = f47.sum()/f3.sum()\n",
    "avg_case_size = f51.mean()\n",
    "avg_fami_mbr = f39.median()\n",
    "avg_14m_per = per['14m_per'].median()\n",
    "\n",
    "def diagnose_recommend(x, avg_rid_per, avg_rep_per, avg_case_size, avg_fami_mbr, avg_14m_per):\n",
    "    out = []\n",
    "    if x[6]/3 >= 600000000/12:\n",
    "        out.append(\"Chúc mừng bạn!\")\n",
    "        out.append(\"Bạn là một trong những Đại lý Manulife Pro Bạch kim hàng đầu của Manulife - điều này có nghĩa là bạn là người giỏi nhất trong số những người giỏi nhất!\")\n",
    "        out.append(\"Bạn đang đi đúng hướng để giữ vững hạng Bạch kim vào kỳ đánh giá tiếp theo vào \" + x[9] + \".\")\n",
    "        out.append(\"Hãy giữ vững phong độ để nhận được khoản Thưởng Năng Suất Xuất Sắc Tháng dành cho đại lý Manulife Pro. Dưới đây là một số gợi ý khai thác thêm hợp đồng  dành cho bạn.\")\n",
    "    elif (x[6]/3 > 0)&(x[7] > 0):\n",
    "        out.append(\"Hiệu suất bán hàng của bạn trong 3 tháng qua dường như thấp hơn khả năng của bạn nhưng đừng lo lắng; chúng tôi ở đây để hỗ trợ bạn. Dưới đây là một số ý tưởng dành cho bạn:\")\n",
    "        if (x[0] <= avg_rid_per - 0.1)&(len(out) < 4):\n",
    "            out.append(\"Bán nhiều sản phẩm bỗ trợ hơn! Bạn đã bán \" + str(int(x[0]*100)) + \"% sản phẩm bỗ trợ, so với \" + str(int(avg_rid_per*100)) + \"% của các Đại lý Bạch kim khác .\")\n",
    "        if (x[1] <= avg_rep_per - 0.1)&(len(out) < 4):\n",
    "            out.append(\"Bán chéo cho khách hàng hiện tại của bạn! Bạn đã bán \" + str(int(x[1]*100)) + \"% cho khách hàng hiện tại, so với \" + str(int(avg_rep_per*100)) + \"% của các đại lý Bạch kim khác.\")\n",
    "        if (x[3] <= avg_case_size*0.7)&(len(out) < 4):\n",
    "            out.append(\"Hãy cân nhắc để mở rộng nguồn khách hàng chất lượng cao của bạn! Độ lớn hợp đồng trung bình của bạn là \" + str(int(x[3]/100000)/10) + \"M, so với \" + str(int(avg_case_size/1000000)) + \"M của các đại lý Bạch kim khác.\")\n",
    "        if (x[4] < avg_fami_mbr)&(len(out) < 4):\n",
    "            out.append(\"Cơ hội cho bạn khai thác hợp đồng từ các thành viên trong gia đình khách hàng! Bạn đã bán cho \" + str(int(x[4])) + \" nhóm thành viên trong gia đình so với \" + str(int(avg_fami_mbr)) + \" của các đại lý Bạch kim khác.\")\n",
    "        if (x[2] <= avg_14m_per - 0.1)&(len(out) < 4):\n",
    "            out.append(\"Hãy cải thiện chất lượng bán hàng của bạn! \" + str(int((1-x[2])*100)) + \"% hợp đồng bạn đã bán bị mất hiệu lực sau năm đầu tiên, so với \" + str(int((1-avg_14m_per)*100)) + \"% đối với các đại lý Bạch kim khác.\")\n",
    "        if len(out) < 4:\n",
    "            out.append(\"Đừng do dự! Hãy đem báo cáo này đến để tham vấn với người quản lý hoặc cố vấn của bạn để họ có thể giúp bạn quay lại đường đua.\")\n",
    "        if len(out) < 4:\n",
    "            out.append(\"Có rất nhiều tài liệu học tập và phát triển kỹ năng thực tế trên Manuacademy đang chờ bạn khám phá!\")\n",
    "        if len(out) < 4:\n",
    "            out.append(\"Bạn hãy tin vào sức mạnh và sức bật của bản thân!\")\n",
    "    else:\n",
    "        out.append(\"Bạn \" + x[10] + \" ơi!, Bạn ở đâu rồi? Chúng tôi rất nhớ bạn và tin rằng bạn sẽ trở lại lợi hại hơn xưa!\")\n",
    "        out.append(\"Là một Pro Bạch Kim, bạn là thành viên của nhóm đại lý xuất sắc nhất với những đặc quyền riêng của Manulife Pro dành cho bạn.\")\n",
    "        out.append(\"Hãy đến ngay với cấp quản lý của bạn để tham vấn cách phù hợp nhất giúp bạn quay lại cuộc đua và chinh phục những đỉnh cao mới.\")\n",
    "        out.append(\"Bạn hãy tin vào sức mạnh và sức bật của bản thân!\")\n",
    "    return out\n",
    "\n",
    "rec = pd.concat([agt.set_index('wa_cd_1')['tier'], \n",
    "                (f.fillna(0)['last_3m_rid'] / f['last_3m_ape']),\n",
    "                (f.fillna(0)['last_6m_rep'] / f['last_6m_ape']),\n",
    "                per.set_index(['agt_cd'])['14m_per'],\n",
    "                f['last_6m_pol_size'],\n",
    "                f['last_6m_fam'],\n",
    "                f['last_6m_prd'],\n",
    "                f.fillna(0)['last_3m_ape'],\n",
    "                f.fillna(0)['last_3m_pol'],\n",
    "                f.fillna(0)['last_yr_pol_size'],\n",
    "                agt.set_index('wa_cd_1')['next_qualify_check'],\n",
    "                agt.set_index('wa_cd_1')['agt_nm']\n",
    "                ], axis = 1)\n",
    "rec.columns = ['level', 'rid','rep','14m_per','last_6m_pol_size','last_6m_fam','last_6m_prd','last_3m_ape','last_3m_pol','last_yr_pol_size',\n",
    "               'next_qualify_check', 'agt_name']\n",
    "rec['zip'] = list(zip(rec['rid'],\n",
    "                      rec['rep'],\n",
    "                      rec['14m_per'],\n",
    "                      rec['last_6m_pol_size'],\n",
    "                      rec['last_6m_fam'],\n",
    "                      rec['last_6m_prd'],\n",
    "                      rec['last_3m_ape'],\n",
    "                      rec['last_3m_pol'],\n",
    "                      rec['last_yr_pol_size'],\n",
    "                      rec['next_qualify_check'],\n",
    "                      rec['agt_name']\n",
    "                      ))\n",
    "rec['diag_list'] = rec['zip'].map(lambda x: diagnose_recommend(x, avg_rid_per, avg_rep_per, avg_case_size, avg_fami_mbr, avg_14m_per))\n",
    "rec['diag_0'] = rec['diag_list'].map(lambda x: x[0])\n",
    "rec['diag_1'] = rec['diag_list'].map(lambda x: x[1])\n",
    "rec['diag_2'] = rec['diag_list'].map(lambda x: x[2])\n",
    "rec['diag_3'] = rec['diag_list'].map(lambda x: x[3])\n",
    "rec = rec.reset_index().rename(columns = {'index':'agt_cd'})\n",
    "rec['report_month'] = mth_partition\n",
    "pd.merge(mp[['agt_cd']], rec, on = 'agt_cd', how = 'left').to_csv(f'{out_path}{snapshot}/vn_mp_recommend_vn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22b250cb-b598-4207-844c-4464a96fc3b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ad hoc processing"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "prepare_data_automation_prod",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
